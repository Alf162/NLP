{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "from nltk.tokenize import wordpunct_tokenize \n",
    "from itertools import chain\n",
    "import nltk\n",
    "import sklearn_crfsuite\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "import pickle\n",
    "from nltk import stem\n",
    "from nltk import word_tokenize\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import json\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def word2features_per(sent, i):\n",
    "    word = sent[i][0]\n",
    "    postag = sent[i][1]\n",
    "    word_ = stemmer.stem(word)\n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "        'word.ismon():': is_month(word_),\n",
    "        'word.lower()': word.lower(),\n",
    "        'word[-3:]': word[-3:],\n",
    "        'word[-2:]': word[-2:],\n",
    "        'word.isupper()': word.isupper(),\n",
    "        'word.istitle()': word.istitle(),\n",
    "        'word.isdigit()': word.isdigit(),\n",
    "        'postag': postag,\n",
    "        'postag[:2]': postag[:2],\n",
    "    }\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][0]\n",
    "        postag1 = sent[i-1][1]\n",
    "        word_l1 = word1.lower()\n",
    "        word1_ = stemmer.stem(word1)\n",
    "        features.update({\n",
    "            '-1:word.lower()': word1.lower(),\n",
    "            '-1:word.ismon():': is_month(word1_),\n",
    "            '-1:word.istitle()': word1.istitle(),\n",
    "            '-1:word.isupper()': word1.isupper(),\n",
    "            '-1:word.isdigit()': word1.isdigit(),\n",
    "            '-1:postag': postag1,\n",
    "            '-1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True\n",
    "\n",
    "    if i < len(sent)-1:\n",
    "        word2 = sent[i+1][0]\n",
    "        postag2 = sent[i+1][1]\n",
    "        word_l1 = word2.lower()\n",
    "        word2_ = stemmer.stem(word2)\n",
    "        features.update({\n",
    "            '+1:word.lower()': word2.lower(),\n",
    "            '+1:word.ismon():': is_month(word2_),\n",
    "            '+1:word.istitle()': word2.istitle(),\n",
    "            '+1:word.isupper()': word2.isupper(),\n",
    "            '+1:word.isdigit()': word2.isdigit(),\n",
    "            '+1:postag': postag2,\n",
    "            '+1:postag[:2]': postag2[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = True\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = \"\"\n",
    "stemmer = nltk.PorterStemmer()\n",
    "def is_month(mon):\n",
    "    mons = np.array(['january', 'february', 'march', 'april', 'may', 'june', 'jule', 'august', 'september', 'october', 'november', 'december', 'jan', 'feb', 'mar', 'apr', 'may', 'jun', 'jul', 'aug', 'sep', 'oct', 'nov', 'dec'])\n",
    "    return mon in mons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sent2features_per(sent):\n",
    "    return [word2features_per(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for token, postag, label in sent]\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, postag, label in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file = open(\"files/crf_model\",'rb')\n",
    "crf_per = pickle.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mod_txt(txt):\n",
    "    text_n = wordpunct_tokenize(txt)\n",
    "    frames = []\n",
    "    for w, ch in zip(text_n, nltk.pos_tag(text_n)):\n",
    "        frames.append([w, ch[1].replace(\",\", \"ZPT\").replace(\".\", \"TCHK\").replace(\"?\", \"VOPR\").replace(\":\", \"DVTC\").replace(\"!\", \"VOSKL\").replace(\";\", \"TZPT\").replace(\"(\", \"SKBL\").replace(\")\", \"SKBR\")])\n",
    "    return np.array(frames), text_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# функция удаляет найденные даты из тестового описания и формирует из них отдельный массив\n",
    "def del_time(txt):\n",
    "    dates = []\n",
    "    mod_t, text_ = mod_txt(txt)\n",
    "    X_test = [sent2features_per(mod_t)]\n",
    "    res = crf_per.predict(X_test)\n",
    "    indices_b = [i for i, x in enumerate(res[0]) if x == \"B-TIME\"]\n",
    "    indices_i = [i for i, x in enumerate(res[0]) if x == \"I-TIME\"]\n",
    "    for i in indices_b:\n",
    "        if (i+1) in indices_i:\n",
    "            dates.append(text_[i] + \" \" + text_[i+1])\n",
    "            text_[i+1] = \"\"\n",
    "        else:\n",
    "            dates.append(text_[i])\n",
    "        text_[i] = \"\"\n",
    "    return ' '.join(text_), dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_str(string):\n",
    "    string = re.sub(ur\"[^A-Za-z]\", \" \", string)\n",
    "    string = re.sub(r\"\\'s\", \" \\'s\", string)\n",
    "    string = re.sub(r\"\\'ve\", \" \\'ve\", string)\n",
    "    string = re.sub(r\"n\\'t\", \" n\\'t\", string)\n",
    "    string = re.sub(r\"\\'re\", \" \\'re\", string)\n",
    "    string = re.sub(r\"\\'d\", \" \\'d\", string)\n",
    "    string = re.sub(r\"\\'ll\", \" \\'ll\", string)\n",
    "    string = re.sub(r\",\", \" , \", string)\n",
    "    string = re.sub(r\"!\", \" ! \", string)\n",
    "    string = re.sub(r\"\\(\", \" \\( \", string)\n",
    "    string = re.sub(r\"\\)\", \" \\) \", string)\n",
    "    string = re.sub(r\"\\?\", \" \\? \", string)\n",
    "    string = re.sub(r\"\\s{2,}\", \" \", string)\n",
    "    return string.strip().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file = open(\"files/tf_model\",'rb')\n",
    "vect_ = pickle.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Используется не весь файл, а только 1500 записей, ноутбук слабенький, тормозит сильно\n",
    "dt = json.loads(open('test.json').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "# Проход по всем записям и формирование нового массива словарей\n",
    "for dt_ in dt:\n",
    "    row = \" \".join(dt_[\"attributes\"][0][\"row\"][\"titles\"])\n",
    "    column = \" \".join(dt_[\"attributes\"][0][\"column\"][\"titles\"])\n",
    "    table = dt_[\"attributes\"][0][\"table\"]\n",
    "    t1, d1 = del_time(row)\n",
    "    t2, d2 = del_time(column)\n",
    "    t3, d3 = del_time(table)\n",
    "    t = {}\n",
    "    t[\"id\"] = dt_[\"_id\"][\"$oid\"]\n",
    "    t[\"semanticId\"] = dt_['semanticId'][\"$oid\"]\n",
    "    t[\"placeId\"] = dt_['placeId'][\"$oid\"]\n",
    "    t[\"txt\"] = vect_.transform([t1+\" \"+t2+\" \"+t3])\n",
    "    t[\"dt\"] = d1+d2+d3\n",
    "    result.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_progress(sequence, every=None, size=None, name='Items'):\n",
    "    from ipywidgets import IntProgress, HTML, VBox\n",
    "    from IPython.display import display\n",
    "\n",
    "    is_iterator = False\n",
    "    if size is None:\n",
    "        try:\n",
    "            size = len(sequence)\n",
    "        except TypeError:\n",
    "            is_iterator = True\n",
    "    if size is not None:\n",
    "        if every is None:\n",
    "            if size <= 200:\n",
    "                every = 1\n",
    "            else:\n",
    "                every = int(size / 200)     # every 0.5%\n",
    "    else:\n",
    "        assert every is not None, 'sequence is iterator, set every'\n",
    "\n",
    "    if is_iterator:\n",
    "        progress = IntProgress(min=0, max=1, value=1)\n",
    "        progress.bar_style = 'info'\n",
    "    else:\n",
    "        progress = IntProgress(min=0, max=size, value=0)\n",
    "    label = HTML()\n",
    "    box = VBox(children=[label, progress])\n",
    "    display(box)\n",
    "\n",
    "    index = 0\n",
    "    try:\n",
    "        for index, record in enumerate(sequence, 1):\n",
    "            if index == 1 or index % every == 0:\n",
    "                if is_iterator:\n",
    "                    label.value = '{name}: {index} / ?'.format(\n",
    "                        name=name,\n",
    "                        index=index\n",
    "                    )\n",
    "                else:\n",
    "                    progress.value = index\n",
    "                    label.value = u'{name}: {index} / {size}'.format(\n",
    "                        name=name,\n",
    "                        index=index,\n",
    "                        size=size\n",
    "                    )\n",
    "            yield record\n",
    "    except:\n",
    "        progress.bar_style = 'danger'\n",
    "        raise\n",
    "    else:\n",
    "        progress.bar_style = 'success'\n",
    "        progress.value = index\n",
    "        label.value = \"{name}: {index}\".format(\n",
    "            name=name,\n",
    "            index=str(index or '?')\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "# Формирование обучающей выборки, где используется два признака, близость векторных представлений текстовых описаний \n",
    "# и нормированное пересечение множеств дат\n",
    "for i in log_progress(range(train)):\n",
    "    for j in range(train):\n",
    "        if i!=j:\n",
    "            temp_arr = []\n",
    "            temp_arr.append(cosine_similarity(result[i][\"txt\"].todense(), result[j][\"txt\"].todense())[0][0])\n",
    "            max_len = max(len(result[i][\"dt\"]), len(result[j][\"dt\"]))\n",
    "            if max_len == 0:\n",
    "                temp_arr.append(0)\n",
    "            else:\n",
    "                temp_arr.append(len(set.intersection(set(result[i][\"dt\"]), set(result[j][\"dt\"])))/float(max_len))\n",
    "            X.append(temp_arr)\n",
    "            if result[i][\"semanticId\"] == result[j][\"semanticId\"] or result[i][\"placeId\"] == result[j][\"placeId\"]:\n",
    "                y.append(1)\n",
    "            else:\n",
    "                y.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "y = np.array(y).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2248500, 2)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2248500, 1)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/utils/validation.py:526: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Обучается классификатор и сохраняется на диск\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filehandler = open(\"files/logreg\",\"wb\")\n",
    "pickle.dump(lr, filehandler)\n",
    "filehandler.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "widgets": {
   "state": {
    "ba81baedc52248e29955acb5b2e35dfc": {
     "views": [
      {
       "cell_index": 13
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
